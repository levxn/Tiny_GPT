{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# from googlesearch import search\n",
    "\n",
    "# # Function to perform a Google search and extract snippets\n",
    "\n",
    "\n",
    "# def google_search(query):\n",
    "#     results = []\n",
    "#     for result in search(query, num_results=num_results):\n",
    "#         results.append(result)\n",
    "#     return results\n",
    "\n",
    "\n",
    "# # Example usage:\n",
    "# query = input('Question: ')\n",
    "# num_results = 5  # Number of search results to retrieve\n",
    "\n",
    "# search_results = google_search(query)\n",
    "\n",
    "# # Print the search results\n",
    "# for index, result in enumerate(search_results, start=1):\n",
    "#     print(f\"Result {index}: {result}\")\n",
    "\n",
    "# # You can parse and extract information from the search results as needed\n",
    "\n",
    "import re\n",
    "from googlesearch import search\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Function to perform a Google search and extract snippets\n",
    "\n",
    "\n",
    "def google_search_and_extract_text(query):\n",
    "    results = []\n",
    "    for result in search(query, num_results=num_results):\n",
    "        try:\n",
    "            # Send a GET request to the search result URL\n",
    "            response = requests.get(result)\n",
    "            # Check if the request was successful (status code 200)\n",
    "            if response.status_code == 200:\n",
    "                # Parse the HTML content of the page\n",
    "                soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "                # Extract and store text content (excluding HTML tags)\n",
    "                text_content = soup.get_text()\n",
    "                results.append(text_content)\n",
    "                # break\n",
    "            else:\n",
    "                print(f\"Failed to retrieve content from {result}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error while fetching content from {result}: {e}\")\n",
    "    return results\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "query = input('Question: ')\n",
    "num_results = 5  # Number of search results to retrieve\n",
    "search_results = google_search_and_extract_text(query)\n",
    "# Print the extracted text content from the search results\n",
    "t = []\n",
    "# for index, text_content in enumerate(search_results, start=1):\n",
    "#     s = re.sub(r'\\s+', ' ', text_content)\n",
    "#     # print(f\"Result {index}:\\n{s}\")\n",
    "#     t.append(s)\n",
    "# print(' '.join(t))\n",
    "\n",
    "for text_content in search_results:\n",
    "    t.append(re.sub(r'\\s+', ' ', text_content))\n",
    "\n",
    "# print(f\"Result:\\n{''.join(t)}\")\n",
    "print(len(t))\n",
    "\n",
    "# print(re.sub(r'\\s+', ' ',\" \".join(search_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141358\n"
     ]
    }
   ],
   "source": [
    "a = ''.join(t)\n",
    "print(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141358\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(len(t[0]) + len(t[1]) + len(t[2]) + len(t[3]) + len(t[4]) + len(t[5]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141358"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = ''.join(t)\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\SNU\\Self_Project\\Image_Stegano\\chatbot.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 55>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SNU/Self_Project/Image_Stegano/chatbot.ipynb#X13sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m summary \u001b[39m=\u001b[39m generate_summary(ques)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SNU/Self_Project/Image_Stegano/chatbot.ipynb#X13sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39mfor\u001b[39;00m sentence \u001b[39min\u001b[39;00m summary:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/SNU/Self_Project/Image_Stegano/chatbot.ipynb#X13sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     \u001b[39mprint\u001b[39m(re\u001b[39m.\u001b[39;49msub(\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39ms+\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m'\u001b[39;49m,sentence))\n",
      "File \u001b[1;32mc:\\Users\\LEVIN M S\\AppData\\Local\\Programs\\Python\\Python310\\lib\\re.py:209\u001b[0m, in \u001b[0;36msub\u001b[1;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msub\u001b[39m(pattern, repl, string, count\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, flags\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[0;32m    203\u001b[0m     \u001b[39m\"\"\"Return the string obtained by replacing the leftmost\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[39m    non-overlapping occurrences of the pattern in string by the\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[39m    replacement repl.  repl can be either a string or a callable;\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[39m    if a string, backslash escapes in it are processed.  If it is\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[39m    a callable, it's passed the Match object and must return\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[39m    a replacement string to be used.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 209\u001b[0m     \u001b[39mreturn\u001b[39;00m _compile(pattern, flags)\u001b[39m.\u001b[39;49msub(repl, string, count)\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import spacy\n",
    "from testing import google_search_and_extract_text\n",
    "from string import punctuation\n",
    "import re\n",
    "\n",
    "def generate_summary(text):\n",
    "    extra_words = list(STOP_WORDS) + list(punctuation) + ['\\n']\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc = ' '.join(google_search_and_extract_text(text))\n",
    "    docx = nlp(doc)\n",
    "    all_words = [word.text for word in docx]\n",
    "    Freq_word = {}\n",
    "\n",
    "    for w in all_words:\n",
    "        w1 = w.lower()\n",
    "        if w1 not in extra_words and w1.isalpha():\n",
    "            if w1 in Freq_word.keys():\n",
    "                Freq_word[w1] += 1\n",
    "            else:\n",
    "                Freq_word[w1] = 1\n",
    "\n",
    "    val = sorted(Freq_word.values())\n",
    "    max_freq = val[-3:]\n",
    "\n",
    "    for word in Freq_word.keys():\n",
    "        Freq_word[word] = (Freq_word[word] / max_freq[-1])\n",
    "\n",
    "    sent_strength = {}\n",
    "    for sent in docx.sents:\n",
    "        for word in sent:\n",
    "            if word.text.lower() in Freq_word.keys():\n",
    "                if sent in sent_strength.keys():\n",
    "                    sent_strength[sent] += Freq_word[word.text.lower()]\n",
    "                else:\n",
    "                    sent_strength[sent] = Freq_word[word.text.lower()]\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    top_sentences = (sorted(sent_strength.values())[::-1])\n",
    "    top30percent_sentence = int(0.3 * len(top_sentences))\n",
    "    top_sent = top_sentences[:top30percent_sentence]\n",
    "\n",
    "    summary = []\n",
    "    for sent, strength in sent_strength.items():\n",
    "        if strength in top_sent:\n",
    "            summary.append(sent)\n",
    "        else:\n",
    "            continue\n",
    "    return summary\n",
    "\n",
    "# Example usage:\n",
    "ques = input('type: ')\n",
    "summary = generate_summary(ques)\n",
    "for sentence in summary:\n",
    "    print(re.sub(r'\\s+', ' ',sentence.text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "z =[]\n",
    "for sentence in summary:\n",
    "    z.append(re.sub(r'\\s+', ' ',sentence.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
